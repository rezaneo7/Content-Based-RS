{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"direction:rtl;line-height:300%; font-family: Yas\">\n",
    "    <font face=\"XB Zar\" size=5>\n",
    "        <div style=\"direction:rtl;line-height:300%; font-family: Yas\">\n",
    "            <font   size=5>\n",
    "                <div align=center>\n",
    "                    <font  size=۲۰>\n",
    "                        <p></p>\n",
    "                            درس آنالیز داده ها\n",
    "                    </font>\n",
    "                    <br>\n",
    "                    <font>\n",
    "                        دانشگاه صنعتی شریف - دانشکده مهندسی برق\n",
    "                    </font>\n",
    "                    <br>\n",
    "                    <font color=blue>\n",
    "                        تمرین دوم \n",
    "                    </font>\n",
    "                    <br>\n",
    "                     ۱۳۹۹\n",
    "                </div>\n",
    "            </font>\n",
    "        </div>\n",
    "    </font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Name : Reza Ramezanpour\n",
    "## Student ID: 95101558"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in f:\\python\\lib\\site-packages (3.5)Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: regex in f:\\python\\lib\\site-packages (from nltk) (2020.6.8)\n",
      "Requirement already satisfied: tqdm in f:\\python\\lib\\site-packages (from nltk) (4.47.0)\n",
      "\n",
      "Requirement already satisfied: joblib in f:\\python\\lib\\site-packages (from nltk) (0.16.0)\n",
      "Requirement already satisfied: click in f:\\python\\lib\\site-packages (from nltk) (7.1.2)\n"
     ]
    }
   ],
   "source": [
    "pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sci\n",
    "import nltk\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n",
    "# 19 is completely random\n",
    "np.random.seed(19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\ramaz\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ramaz\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = fetch_20newsgroups(remove=(\"header\",\"footers\",\"quotes\"), return_X_y=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"direction: rtl; line-height: 300%; font-family: Yas\">\n",
    "    <font  size=4>\n",
    "از تابع\n",
    "       Tokenizer\n",
    "        می توانند استفاده کنید تا یک رشته متنی را به \n",
    "    لیستی از لغات تبدیل کنید.\n",
    "    این تابع \n",
    "        stop word \n",
    "        ها\n",
    "        و علامت های نگارشی را حذف می کنید.\n",
    "    و ریشه لغات را جایگزین می‌کند.\n",
    "    </font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['wonder', 'anyon', 'could', 'enlighten']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def Tokenizer(str_input):\n",
    "    str_input = str_input.lower()\n",
    "    words = word_tokenize(str_input)\n",
    "    #remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = [w for w in words if not w in stop_words]\n",
    "    #stem the words\n",
    "    porter_stemmer = nltk.PorterStemmer()\n",
    "    words = [porter_stemmer.stem(w) for w in words if w.isalpha()]\n",
    "    return words\n",
    "\n",
    "#example:\n",
    "Tokenizer(\"I was wondering if anyone out there could enlighten me on ...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenizing each news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_words = []\n",
    "\n",
    "for text in X:\n",
    "    text_words.append(Tokenizer(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using TF-IDF for Vectorization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(analyzer=lambda x:[w for w in x])    \n",
    "tf_idf_text = np.array(tfidf.fit_transform(text_words).todense())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"direction: rtl; line-height: 300%; font-family: Yas\">\n",
    "    <font  size=4>\n",
    "     تابع زیر را تکمیل کنید. باید یک متن از متن های موجود در   \n",
    "    مجموعه داده \n",
    "    newsgroups\n",
    "    بگیرد و ۱۰ متن مشابه برگرداند.\n",
    "    در استفاده از هر \n",
    "    package \n",
    "    ای\n",
    "        برای\n",
    "        LSH\n",
    "        مختار هستید.\n",
    "    توجه داشته باشید که فقط باید از متون برای تشخیص شباهت\n",
    "        استفاده کنید و از \n",
    "        بردارY \n",
    "        (tag)\n",
    "       که به هر\n",
    "        متن\n",
    "        منسوب  \n",
    "      شده است باید در ارزیابی مدل استفاده کنید  \n",
    "    </font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Hyperplanes LSH "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"direction: rtl; line-height: 300%; font-family: Yas\">\n",
    "    <font  size=4>\n",
    "    این بخش بصورت مفصل در فایل Report_Programming\n",
    "    توضیح داده شده است.\n",
    "    </font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "# convert a vector to sign(vector)\n",
    "def binary_conv(row):\n",
    "    \n",
    "    return [1 if x >= 0 else 0 for x in row]\n",
    "\n",
    "# convert a binary vector to int\n",
    "def bin2dec(row):\n",
    "    \n",
    "    return int(\"\".join(str(x) for x in row), 2)\n",
    "\n",
    "def similar_text(text, list_similar_vector, list_similar_keys, k, text_id):\n",
    "    \n",
    "    # holding cosine values\n",
    "    cosine_val = []\n",
    "    cosine_key = []\n",
    "        \n",
    "    for i in range(len(list_similar_keys)):\n",
    "\n",
    "        if(list_similar_keys[i] == text_id):\n",
    "            continue\n",
    "            \n",
    "        # cosine sim \n",
    "        cosine_sim = 1 - cosine(text, list_similar_vector[i])\n",
    "\n",
    "        # if this vector is more similar update nearest values\n",
    "\n",
    "        \n",
    "        cosine_val.append(cosine_sim)\n",
    "        cosine_key.append(list_similar_keys[i])\n",
    "    \n",
    "    if(len(cosine_key) <= k):\n",
    "        return cosine_key\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        k_index = np.argsort(cosine_key)[::-1][:k]\n",
    "        \n",
    "        return [cosine_key[ind] for ind in k_index]\n",
    "        \n",
    "\n",
    "class LSH:\n",
    "    def __init__(self, num_planes=4, num_hashes=20): \n",
    "      \n",
    "        \n",
    "        # minimum is 8 due to question\n",
    "        self.num_planes = num_planes\n",
    "\n",
    "        # number of hash tables\n",
    "        self.num_hashes = num_hashes\n",
    "        \n",
    "        # signature matrix\n",
    "        self.signature_matrix = []\n",
    "        self.signature_matrix_keys = []\n",
    "        \n",
    "        # norm of planes (considering planes passing through origin)\n",
    "        self.norm_planes = []\n",
    "        \n",
    "    def random_hashing(self):\n",
    "        \n",
    "\n",
    "        for i in range(self.num_hashes):\n",
    "\n",
    "            # generating norm of planes\n",
    "            self.norm_planes.append(np.random.normal(size = (self.num_planes, tf_idf_text.shape[1])))\n",
    "\n",
    "            # baskets\n",
    "            baskets_vector = {}\n",
    "            baskets_key = {}\n",
    "\n",
    "            # number of baskets\n",
    "            num_basket = 2 ** self.num_planes \n",
    "\n",
    "            # making a list for holding vectors\n",
    "            for j in range(num_basket):\n",
    "                baskets_vector[j] = []\n",
    "                baskets_key[j] = []\n",
    "\n",
    "            # finding side of each point from hyperplanes\n",
    "            side_vector = tf_idf_text @ self.norm_planes[i].T\n",
    "\n",
    "            # convert it to binary\n",
    "            binary_side = np.apply_along_axis(binary_conv, 1, side_vector)\n",
    "\n",
    "            # convert binary to decimal as a hash value\n",
    "            hash_value = np.apply_along_axis(bin2dec, 1, binary_side)\n",
    "\n",
    "            # assign to baskets\n",
    "            for j in range(len(hash_value)):\n",
    "                baskets_vector[hash_value[j]].append(tf_idf_text[j, :])\n",
    "                baskets_key[hash_value[j]].append(j)\n",
    "\n",
    "            self.signature_matrix.append(baskets_vector)\n",
    "            self.signature_matrix_keys.append(baskets_key)\n",
    "\n",
    "    \n",
    "    def recommend(self, text_id, search_text,k):\n",
    "    \n",
    "       \n",
    "\n",
    "        # list of similar vectors to each text\n",
    "        list_similar_vector = []\n",
    "        list_similar_keys = []\n",
    "\n",
    "        for i in range(self.num_hashes):\n",
    "\n",
    "            # finding side of each search word from hyperplanes\n",
    "            side_vector = search_text @ self.norm_planes[i].T\n",
    "\n",
    "            # convert it to binary\n",
    "            binary_side = [1 if x >= 0 else 0 for x in side_vector]\n",
    "\n",
    "            # convert binary to decimal as a hash value\n",
    "            hash_value = int(\"\".join(str(x) for x in binary_side), 2) \n",
    "\n",
    "            # hash table for i-th hash \n",
    "            hash_table = self.signature_matrix[i]\n",
    "            hash_keys = self.signature_matrix_keys[i]\n",
    "\n",
    "            # related baskets to word\n",
    "            basket_vectors = hash_table[hash_value]\n",
    "            basket_keys = hash_keys[hash_value]\n",
    "\n",
    "\n",
    "            for j in range(len(basket_keys)):\n",
    "\n",
    "                if(basket_keys[j] not in list_similar_keys):\n",
    "                    list_similar_keys.append(basket_keys[j])\n",
    "                    list_similar_vector.append(basket_vectors[j])\n",
    "\n",
    "\n",
    "        return similar_text(search_text, list_similar_vector, list_similar_keys, k, text_id)\n",
    "\n",
    "# 5 number of planes and 20 hash tables\n",
    "lsh = LSH(5, 20)\n",
    "    \n",
    "# hash french pickles into buckets\n",
    "lsh.random_hashing()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"direction: rtl; line-height: 300%; font-family: Yas\">\n",
    "    <font  size=4>\n",
    "دو معیار شناخته شد برای ارزیابی سیستم ها توصیه گر\n",
    "<br>    \n",
    "        mrr (mean reciprocal ranking)\n",
    "<br>\n",
    "        map (mean average precision)\n",
    "<br>\n",
    "       هستند.\n",
    "         تابع های مربوط به این دو معیار پیاده سازی کنید.\n",
    "        در این پیاده سازی فقط می توانید از \n",
    "        numpy\n",
    "        و \n",
    "        scipy \n",
    "        استفاده کنید.\n",
    "        برای توضیح بیشتر می توانید از دو لینک زیر کمک بگیرد.\n",
    "https://en.wikipedia.org/wiki/Mean_reciprocal_rank <br>\n",
    "http://sdsawtelle.github.io/blog/output/mean-average-precision-MAP-for-recommender-systems.html\n",
    "    </font>\n",
    "</div>       \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mrrk(pred_list,real_list):\n",
    "    #mean reciprocal ranking at k\n",
    "    \n",
    "    # len of predictions\n",
    "    q = len(real_list)\n",
    "    \n",
    "    # holding sum of (1 / rank)\n",
    "    sum_rank = 0\n",
    "    \n",
    "    for i in range(q):\n",
    "        \n",
    "        for j in range(10):\n",
    "            \n",
    "            # finding index of first match\n",
    "            if(y[pred_list[i][j]] == real_list[i]):\n",
    "                sum_rank += (1 / (j + 1))\n",
    "                break\n",
    "               \n",
    "    return sum_rank / q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apk(pred_list, real_label):\n",
    "    \n",
    "    gtp = 0\n",
    "    ap_val = 0\n",
    "    \n",
    "    for i in range(len(pred_list)):\n",
    "        \n",
    "        if(y[pred_list[i]] == real_label):\n",
    "            gtp += 1\n",
    "            \n",
    "            ap_val += (gtp / (i + 1))\n",
    "            \n",
    "    if gtp != 0 :\n",
    "        \n",
    "        return ap_val / gtp\n",
    "    else:\n",
    "        return 0\n",
    "            \n",
    "            \n",
    "\n",
    "def mapk(pred_list,real_list):\n",
    "    #mean average precision at k\n",
    "    \n",
    "    # len of predictions\n",
    "    q = len(real_list)\n",
    "    \n",
    "    sum_ap = 0 \n",
    "    \n",
    "    for i in range(q):\n",
    "        \n",
    "        sum_ap += apk(pred_list[i], real_list[i])\n",
    "        \n",
    "    return sum_ap / q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"direction: rtl; line-height: 300%; font-family: Yas\">\n",
    "    <font  size=4>\n",
    "اکنون ۱۰۰ متن دلخواه را انتخاب کرد و برای هر کدام ۱۰ پیشنهاد مشابه ارائه دهید\n",
    "        و با دو معیار بالا مبتی بر بودن و نبودن در یک \n",
    "        category\n",
    "        سیستم خود را ارزیابی کنید.\n",
    "    مراقب باشد خود متنی را  که قرار است متون مشابه را برای آن ارائه دهید را \n",
    "        filter\n",
    "        کنید.\n",
    "    </font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating 100 random numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_news_id = np.random.choice(len(tf_idf_text), 100, replace=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating list of recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# holding recommendations for each news\n",
    "pred_list = []\n",
    "\n",
    "# number of recommendations\n",
    "k = 10\n",
    "\n",
    "for ind in random_news_id:\n",
    "    pred_list.append(lsh.recommend(ind, tf_idf_text[ind], k))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating list of real labels ( categories )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_list = []\n",
    "\n",
    "for ind in range(100):\n",
    "    real_list.append(y[ind])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MRR "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12876190476190474"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mrrk(pred_list, real_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12055158730158728"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapk(pred_list, real_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"direction: rtl; line-height: 300%; font-family: Yas\">\n",
    "    <font  size=4>\n",
    "        \n",
    "همانطور که می بینید با مدل ساده ای که پیاده کردیم، نتیجه خوبی برای این سیستم توصیه گر بدست نیاوردیم که این نشان دهنده این است که از الگوریتم های پیچیده تری باید استفاده کرد.\n",
    "    </font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"direction: rtl; line-height: 300%; font-family: Yas\">\n",
    "    <font  size=4>\n",
    "              میزان mrr\n",
    "        کم است و این بدان معنا است که در لیست ده تایی ما به طور متوسط یک تا دو عدد آیتم مرتبط وجود دارد که عدد پایینی است.\n",
    "    </font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <div style=\"direction: rtl; line-height: 300%; font-family: Yas\">\n",
    "    <font  size=4>\n",
    "               همچنین میزان map\n",
    "        نیز کم است و این بدان معنی است که آیتم هایی که با ارزش بیشتر توصیه می شوند که یعنی در صدر لیست قرار دارند کمتر مرتبط هستند و یا می توان این طور معنی کرد که آیتم های مرتبط جایگاه بالایی در سیستم توصیه گر ندارند.\n",
    "    </font>\n",
    "</div>\n",
    "\n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <div style=\"direction: rtl; line-height: 300%; font-family: Yas\">\n",
    "    <font  size=4>\n",
    "               در نهایت شاید بهتر باشد از روش های بهتری برای embedding \n",
    "        بردارها و نیز روش های بهتری برای hashing\n",
    "        مثل LSH Forest\n",
    "        استفاده کنیم.\n",
    "    </font>\n",
    "</div>\n",
    "\n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating My Ranking metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <div style=\"direction: rtl; line-height: 300%; font-family: Yas\">\n",
    "    <font  size=4>\n",
    "               در زیر برای اینکه نشان دهم توابعی که برای محاسبه مقادیر mrr\n",
    "        و map\n",
    "        زده ام درست هستند از توابع آماده استفاده می کنم که نشان می دهند توابع من درست پیاده سازی شده اند\n",
    "    </font>\n",
    "</div>\n",
    "\n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "recom_list = []\n",
    "\n",
    "for i in range(len(real_list)):\n",
    "    vect= []\n",
    "    \n",
    "    for j in range(10):\n",
    "        \n",
    "        if(y[pred_list[i][j]] == real_list[i]):\n",
    "                \n",
    "            vect.append(1)\n",
    "                \n",
    "        else:\n",
    "            vect.append(0)\n",
    "            \n",
    "    recom_list.append(vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_reciprocal_rank(rs):\n",
    "    \"\"\"Score is reciprocal of the rank of the first relevant item\n",
    "    First element is 'rank 1'.  Relevance is binary (nonzero is relevant).\n",
    "    Example from http://en.wikipedia.org/wiki/Mean_reciprocal_rank\n",
    "    >>> rs = [[0, 0, 1], [0, 1, 0], [1, 0, 0]]\n",
    "    >>> mean_reciprocal_rank(rs)\n",
    "    0.61111111111111105\n",
    "    >>> rs = np.array([[0, 0, 0], [0, 1, 0], [1, 0, 0]])\n",
    "    >>> mean_reciprocal_rank(rs)\n",
    "    0.5\n",
    "    >>> rs = [[0, 0, 0, 1], [1, 0, 0], [1, 0, 0]]\n",
    "    >>> mean_reciprocal_rank(rs)\n",
    "    0.75\n",
    "    Args:\n",
    "        rs: Iterator of relevance scores (list or numpy) in rank order\n",
    "            (first element is the first item)\n",
    "    Returns:\n",
    "        Mean reciprocal rank\n",
    "    \"\"\"\n",
    "    rs = (np.asarray(r).nonzero()[0] for r in rs)\n",
    "    return np.mean([1. / (r[0] + 1) if r.size else 0. for r in rs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12876190476190477"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_reciprocal_rank(recom_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_at_k(r, k):\n",
    "    \"\"\"Score is precision @ k\n",
    "    Relevance is binary (nonzero is relevant).\n",
    "    >>> r = [0, 0, 1]\n",
    "    >>> precision_at_k(r, 1)\n",
    "    0.0\n",
    "    >>> precision_at_k(r, 2)\n",
    "    0.0\n",
    "    >>> precision_at_k(r, 3)\n",
    "    0.33333333333333331\n",
    "    >>> precision_at_k(r, 4)\n",
    "    Traceback (most recent call last):\n",
    "        File \"<stdin>\", line 1, in ?\n",
    "    ValueError: Relevance score length < k\n",
    "    Args:\n",
    "        r: Relevance scores (list or numpy) in rank order\n",
    "            (first element is the first item)\n",
    "    Returns:\n",
    "        Precision @ k\n",
    "    Raises:\n",
    "        ValueError: len(r) must be >= k\n",
    "    \"\"\"\n",
    "    assert k >= 1\n",
    "    r = np.asarray(r)[:k] != 0\n",
    "    if r.size != k:\n",
    "        raise ValueError('Relevance score length < k')\n",
    "    return np.mean(r)\n",
    "\n",
    "\n",
    "def average_precision(r):\n",
    "    \"\"\"Score is average precision (area under PR curve)\n",
    "    Relevance is binary (nonzero is relevant).\n",
    "    >>> r = [1, 1, 0, 1, 0, 1, 0, 0, 0, 1]\n",
    "    >>> delta_r = 1. / sum(r)\n",
    "    >>> sum([sum(r[:x + 1]) / (x + 1.) * delta_r for x, y in enumerate(r) if y])\n",
    "    0.7833333333333333\n",
    "    >>> average_precision(r)\n",
    "    0.78333333333333333\n",
    "    Args:\n",
    "        r: Relevance scores (list or numpy) in rank order\n",
    "            (first element is the first item)\n",
    "    Returns:\n",
    "        Average precision\n",
    "    \"\"\"\n",
    "    r = np.asarray(r) != 0\n",
    "    out = [precision_at_k(r, k + 1) for k in range(r.size) if r[k]]\n",
    "    if not out:\n",
    "        return 0.\n",
    "    return np.mean(out)\n",
    "\n",
    "\n",
    "def mean_average_precision(rs):\n",
    "    \"\"\"Score is mean average precision\n",
    "    Relevance is binary (nonzero is relevant).\n",
    "    >>> rs = [[1, 1, 0, 1, 0, 1, 0, 0, 0, 1]]\n",
    "    >>> mean_average_precision(rs)\n",
    "    0.78333333333333333\n",
    "    >>> rs = [[1, 1, 0, 1, 0, 1, 0, 0, 0, 1], [0]]\n",
    "    >>> mean_average_precision(rs)\n",
    "    0.39166666666666666\n",
    "    Args:\n",
    "        rs: Iterator of relevance scores (list or numpy) in rank order\n",
    "            (first element is the first item)\n",
    "    Returns:\n",
    "        Mean average precision\n",
    "    \"\"\"\n",
    "    return np.mean([average_precision(r) for r in rs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1205515873015873"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_average_precision(recom_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
